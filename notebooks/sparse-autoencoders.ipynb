{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# relevant papers/posts\n",
    "- [Toy Models of Superposition](https://transformer-circuits.pub/2022/toy_model/index.html)\n",
    "- [Towards Monosemanticity: Decomposing Language Models With Dictionary Learning](https://transformer-circuits.pub/2023/monosemantic-features/index.html)\n",
    "- [Sparse Autoencoders Find Highly Interpretable Features in Language Models](https://arxiv.org/abs/2309.08600)\n",
    "- [Toward A Mathematical Framework for Computation in Superposition](https://www.lesswrong.com/posts/2roZtSr5TGmLjXMnT/toward-a-mathematical-framework-for-computation-in)\n",
    "- [Neuronpedia](https://neuronpedia.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/feature-superposition.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/superposition-simulates.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/sae-explanation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "from transformer_lens import HookedTransformer\n",
    "from tqdm import tqdm\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from jaxtyping import Float, Int\n",
    "from muutils.dictmagic import condense_tensor_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tensor_dict(d: dict[str, torch.Tensor]) -> None:\n",
    "\tprint(condense_tensor_dict(d, return_format=\"yaml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a subset of the tinystories dataset\n",
    "with open(\"../data/tinystories_10k.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "\tTEXT_DATA: list[str] = f.read().split(\"<|endoftext|>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Python3_11\\Lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model tiny-stories-1M into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "MODEL: HookedTransformer = HookedTransformer.from_pretrained(\"tiny-stories-1M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba839ca0a2847caa227e8c4162219bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Once upon a time, there was a big, little boy. He'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL.generate(\"Once upon a time\", max_new_tokens=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_model=64, n_layers=8, n_heads=16, d_vocab=50257\n"
     ]
    }
   ],
   "source": [
    "d_model: int = MODEL.cfg.d_model\n",
    "n_layers: int = MODEL.cfg.n_layers\n",
    "n_heads: int = MODEL.cfg.n_heads\n",
    "d_vocab: int = MODEL.cfg.d_vocab\n",
    "\n",
    "print(f\"{d_model=}, {n_layers=}, {n_heads=}, {d_vocab=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed:\n",
      "  W_E: (50257, 64)\n",
      "pos_embed:\n",
      "  W_pos: (2048, 64)\n",
      "blocks:\n",
      "  '[0-7]':\n",
      "    attn:\n",
      "      '[W_Q, W_K, W_V]': (16, 64, 4)\n",
      "      W_O: (16, 4, 64)\n",
      "      '[b_Q, b_K, b_V]': (16, 4)\n",
      "      b_O: (64,)\n",
      "      mask: (2048, 2048)\n",
      "      IGNORE: ()\n",
      "    mlp:\n",
      "      W_in: (64, 256)\n",
      "      b_in: (256,)\n",
      "      W_out: (256, 64)\n",
      "      b_out: (64,)\n",
      "unembed:\n",
      "  W_U: (64, 50257)\n",
      "  b_U: (50257,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tensor_dict(MODEL.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at neurons directly\n",
    "\n",
    "first, let's see that superposition is an actual problem in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, cache = MODEL.run_with_cache(TEXT_DATA[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 190, 50257])\n"
     ]
    }
   ],
   "source": [
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks:\n",
      "  '[0-7]':\n",
      "    ln1:\n",
      "      hook_scale: (3, 190, 1)\n",
      "      hook_normalized: (3, 190, 64)\n",
      "    attn:\n",
      "      '[hook_q, hook_k, hook_v, hook_z]': (3, 190, 16, 4)\n",
      "      '[hook_attn_scores, hook_pattern]': (3, 16, 190, 190)\n",
      "    ln2:\n",
      "      hook_scale: (3, 190, 1)\n",
      "      hook_normalized: (3, 190, 64)\n",
      "    mlp:\n",
      "      '[hook_pre, hook_post]': (3, 190, 256)\n",
      "    '[hook_resid_pre, hook_attn_out, hook_resid_mid, hook_mlp_out, hook_resid_post]': (3,\n",
      "      190, 64)\n",
      "ln_final:\n",
      "  hook_scale: (3, 190, 1)\n",
      "  hook_normalized: (3, 190, 64)\n",
      "'[hook_embed, hook_pos_embed]': (3, 190, 64)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tensor_dict(cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(cache[\"blocks.0.hook_resid_post\"][0].flatten().cpu(), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_model = 64\n"
     ]
    }
   ],
   "source": [
    "n_samples: int = 200\n",
    "\n",
    "sample_activations: Float[torch.Tensor, \"len(TEXT_DATA) d_model\"] = torch.zeros(n_samples, d_model)\n",
    "\n",
    "print(f\"{d_model = }\")\n",
    "\n",
    "for idx, text in enumerate(TEXT_DATA[:n_samples]):\n",
    "\tlogits, cache = MODEL.run_with_cache([text])\n",
    "\tsample_activations[idx] = cache[\"blocks.0.hook_resid_post\"][0].mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 64])\n",
      "torch.return_types.topk(\n",
      "values=tensor([0.0115, 0.0020]),\n",
      "indices=tensor([118,  63]))\n",
      "\n",
      "Once upon a time, there was an old dog named Spot. Spot had an itch on his back that he could not scratch. He tried and tried, but his legs were too short to reach the itch.\n",
      "One sunny day, Spot met a friendly cat named Fluffy. Fluffy saw Spot trying to scratch his itch and felt bad for him. Fluffy had an idea. \"I can help you with your itch, Spot,\" said Fluffy. \"Let's share our paws and help each other.\" Spot agreed, and they became friends.\n",
      "Fluffy used her paw to scratch Spot's itch, and he felt so much better. In return, Spot shared his favorite toy with Fluffy, and they played together all day. From that day on, Spot and Fluffy always shared their toys and helped each other when they had itches. And they lived happily ever after.\n",
      "\n",
      "--------------------\n",
      "\n",
      "Once upon a time, there was a clumsy dog named Spot. Spot loved to play and run around. One day, Spot and his family went to camp. Spot was so excited to go on a trip with his family.\n",
      "At camp, Spot played with his ball and made new friends. But one day, he lost his ball in the woods. Spot started to worry. He looked and looked for his ball, but he couldn't find it anywhere.\n",
      "Then, Spot saw a squirrel holding his ball. The squirrel saw how sad Spot was and gave the ball back to him. Spot was so happy! He thanked the squirrel and went back to camp. Spot learned not to worry too much, because things can work out in the end.\n",
      "\n",
      "--------------------\n",
      "\n",
      "\n",
      "\n",
      "Lily and Ben were bored. They wanted to play outside, but it was raining. They looked around the house for something fun to do. They saw a big box in the corner. It had a sign that said \"Do not open\".\n",
      "\"What is in there?\" Lily asked.\n",
      "\"I don't know. Let's find out,\" Ben said.\n",
      "They opened the box and saw many smaller boxes inside. They had holes and flaps and strings. They looked like a maze.\n",
      "\"Wow, this is cool. Let's make a maze with the boxes,\" Lily said.\n",
      "They took out the boxes and arranged them on the floor. They made a long and twisty maze with many turns and dead ends. They crawled inside and explored the maze. They had fun finding each other and hiding and making noises.\n",
      "They did not hear their mom come home. She walked into the living room and saw the mess. She was grumpy.\n",
      "\"What are you doing? Look at this mess. You are not supposed to open that box. It is for the charity sale,\" she said.\n",
      "Lily and Ben came out of the maze. They looked at their mom. They were sorry.\n",
      "\"We are sorry, mom. We were bored. We wanted to play. We discovered a maze in the box. It was fun,\" Lily said.\n",
      "Ben nodded. He said, \"We are sorry, mom. We did not know. We will help you clean up.\"\n",
      "Their mom sighed. She was not so grumpy anymore. She saw that they were just curious and creative. She smiled.\n",
      "\"It's okay, kids. I understand. But next time, please ask me before you open a box. And please be careful with the boxes. They are for a good cause. Now, let's clean up and then we can have a snack. How about that?\" she said.\n",
      "Lily and Ben smiled. They said, \"Okay, mom. Thank you, mom. We love you, mom.\"\n",
      "They hugged their mom and helped her clean up the maze. They learned a lesson and had a snack. They were happy.\n",
      "\n",
      "--------------------\n",
      "\n",
      "\n",
      "\n",
      "Lily and Tom were playing in the bath. They had many toys: a duck, a boat, a frog and a ball. They made the toys swim and splash in the water. They had fun.\n",
      "But then Lily saw something. The water was going down. It was going into a hole. The hole was called a drain. Lily did not like the drain. She was scared of it.\n",
      "\"Tom, look!\" Lily said. \"The water is becoming less. The drain is taking it away. What if it takes us away too?\"\n",
      "Tom looked at the drain. He was not scared of it. He was curious. He wanted to see how it worked.\n",
      "\"Don't worry, Lily,\" Tom said. \"The drain is not bad. It is just a little hole. It cannot take us away. We are too big. Only the water can go through it. See?\"\n",
      "Tom put his hand near the drain. He felt the water pulling his hand. He laughed.\n",
      "\"It tickles!\" Tom said. \"It is like a game. Do you want to try?\"\n",
      "Lily shook her head. She did not want to try. She did not like the game. She wanted the water to stay.\n",
      "\"Tom, stop!\" Lily said. \"I don't like the drain. I don't like the game. I want more water. Please, turn on the tap!\"\n",
      "Tom saw that Lily was sad. He did not want to make her sad. He wanted to make her happy. He turned on the tap. The water came out. It filled the bath again. The toys floated and bobbed. Lily smiled.\n",
      "\"Thank you, Tom,\" Lily said. \"You are a good brother. I like the water. I like the toys. I like you.\"\n",
      "Tom smiled too. He was a good brother. He liked the water. He liked the toys. He liked Lily.\n",
      "They hugged. They played. They forgot about the drain. They were happy.\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "print(sample_activations.shape)\n",
    "\n",
    "chosen_dimension_sample_activations = sample_activations[:, 5]\n",
    "top_k = torch.topk(chosen_dimension_sample_activations, k=2)\n",
    "bottom_k = torch.topk(chosen_dimension_sample_activations, k=2, largest=False)\n",
    "print(top_k)\n",
    "\n",
    "for idx in top_k.indices:\n",
    "\tprint(TEXT_DATA[idx])\n",
    "\tprint('-'*20)\n",
    "\n",
    "for idx in bottom_k.indices:\n",
    "\tprint(TEXT_DATA[idx])\n",
    "\tprint('-'*20)\n",
    "\n",
    "# plt.hist(chosen_dimension_sample_activations.cpu(), bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## finding neurons that activate on a certain feature\n",
    "\n",
    "first, we need to come up with a feature and come up with some positive and negative examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up the sparse autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE(torch.nn.Module):\n",
    "\tdef __init__(self, d_model: int, d_hidden: int):\n",
    "\t\tsuper(SAE, self).__init__()\n",
    "\t\tself.encoder: torch.nn.Module = torch.nn.Sequential(\n",
    "\t\t\ttorch.nn.Linear(d_model, d_hidden, bias=True),\n",
    "\t\t\ttorch.nn.ReLU(),\n",
    "\t\t)\n",
    "\t\tself.decoder: torch.nn.Module = torch.nn.Sequential(\n",
    "\t\t\ttorch.nn.Linear(d_hidden, d_model, bias=True),\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "\t\treturn self.decoder(self.encoder(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.016180742837605067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 0.0015572813135804608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 0.0007762109671602957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 0.0005092821174912388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 0.00047132808322203346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train_sae(\n",
    "\tmodel: HookedTransformer,\n",
    "\tdataset: list[str] = TEXT_DATA[:256],\n",
    "\tbatchsize: int = 16,\n",
    "\tepochs: int = 10,\n",
    "\tsae_hidden: int = 128,\n",
    "\tlearning_rate: float = 1e-3,\n",
    "\tblock_id: int = 0,\n",
    "\tsparsity_coeff: float = 1e-3,\n",
    "\tdevice: torch.device|str = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "):\n",
    "\t# dont keep gradients for the model\n",
    "\tmodel.eval()\n",
    "\td_model: int = model.cfg.d_model\n",
    "\tn_samples: int = len(dataset)\n",
    "\n",
    "\tsae: SAE = SAE(d_model, sae_hidden)\n",
    "\tsae.to(device)\n",
    "\toptimizer: torch.optim.Adam = torch.optim.Adam(sae.parameters(), lr=learning_rate)\n",
    "\treconstruction_loss: torch.nn.Module = torch.nn.MSELoss()\n",
    "\tsparsity_penalty: torch.nn.Module = torch.nn.L1Loss()\n",
    "\tsparsity_target: torch.Tensor = torch.zeros(batchsize, sae_hidden).to(device)\n",
    "\n",
    "\thook_id: str = f\"blocks.{block_id}.hook_resid_post\"\n",
    "\thook_cache: torch.Tensor = torch.zeros(batchsize, d_model).to(device)\n",
    "\n",
    "\tdef hook_fn(x: torch.Tensor, hook: HookPoint):\n",
    "\t\thook_cache = x\n",
    "\t\treturn None # we don't modify the activation\n",
    "\n",
    "\tfor epoch in range(epochs):\n",
    "\t\tepoch_loss: float = 0.0\n",
    "\t\tidx: int = 0\n",
    "\t\tfor batch_idx in tqdm(range(0, n_samples // batchsize)):\n",
    "\t\t\tif idx + batchsize > n_samples:\n",
    "\t\t\t\tbreak\n",
    "\t\t\tbatch = dataset[idx:idx+batchsize]\n",
    "\t\t\tidx += len(batch)\n",
    "\t\t\tmodel.run_with_hooks(\n",
    "\t\t\t\tbatch,\n",
    "\t\t\t\tfwd_hooks=[(\n",
    "\t\t\t\t\thook_id,\n",
    "\t\t\t\t\thook_fn,\n",
    "\t\t\t\t)],\n",
    "\t\t\t\treturn_type=None, # for efficiency\n",
    "\t\t\t)\n",
    "\t\t\tactivations: Float[torch.Tensor, \"batchsize d_model\"] = hook_cache\n",
    "\t\t\t# print(f\"{activations.shape=}\")\n",
    "\t\t\tactivations = activations.detach().to(device)\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\thidden_activations: Float[torch.Tensor, \"len(batch) sae_hidden\"] = sae.encoder(activations)\n",
    "\t\t\treconstructed_activations: Float[torch.Tensor, \"len(batch) d_model\"] = sae.decoder(hidden_activations)\n",
    "\t\t\tloss = reconstruction_loss(reconstructed_activations, activations) + sparsity_coeff * sparsity_penalty(hidden_activations, sparsity_target)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\tepoch_loss += loss.item()\n",
    "\t\t\tdel activations\n",
    "\t\t\tdel hidden_activations\n",
    "\t\t\tdel reconstructed_activations\n",
    "\t\t\tdel loss\n",
    "\t\tprint(f\"Epoch {epoch}: {epoch_loss}\")\n",
    "\n",
    "\treturn sae\n",
    "\n",
    "\n",
    "TRAINED_SAE = train_sae(MODEL, epochs=5, sae_hidden=128, sparsity_coeff=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find features which correspond to a sample of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
